import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime
import os

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏ —Ñ–æ–Ω–¥–∞", layout="wide")

st.title("üìä –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–≤–∏–∂–µ–Ω–∏—è –î–§ –∏ —Å–ø–æ—Å–æ–±–æ–≤ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–≤–∞ —Ñ–∞–π–ª–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —Ñ–æ–Ω–¥–µ.")

# ================== –°–ü–†–ê–í–û–ß–ù–ò–ö–ò –ò–ó –†–ï–ü–û–ó–ò–¢–û–†–ò–Ø ==================

# --- fond.csv ---
fond = pd.read_csv("fond.csv")
fond.columns = fond.columns.str.replace('"', '').str.strip()

# --- main_well.csv ---
main_well = pd.read_csv("main_well.csv")
main_well.columns = main_well.columns.str.replace('"', '').str.strip()
main_well = main_well.rename(columns={'name': '–°–∫–≤–∞–∂–∏–Ω–∞'})

cols_main = ['–°–∫–≤–∞–∂–∏–Ω–∞', 'sedmax_ip', 'lora_id']
missing_main = [c for c in cols_main if c not in main_well.columns]
if missing_main:
    raise ValueError(f"–í main_well.csv –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: {missing_main}")

main_well = (
    main_well[cols_main]
    .drop_duplicates(subset=['–°–∫–≤–∞–∂–∏–Ω–∞'], keep='first')
    .copy()
)

# ================== –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ==================

LOG_PATH = "usage_log.csv"

def log_event(event: str, file1_name: str = "", file2_name: str = "") -> None:
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    row = pd.DataFrame([{
        "timestamp": ts,
        "event": event,
        "file1": file1_name,
        "file2": file2_name,
    }])

    if os.path.exists(LOG_PATH):
        row.to_csv(LOG_PATH, mode="a", header=False, index=False)
    else:
        row.to_csv(LOG_PATH, mode="w", header=True, index=False)

def read_last_logs(n: int = 100) -> pd.DataFrame:
    if not os.path.exists(LOG_PATH):
        return pd.DataFrame(columns=["timestamp", "event", "file1", "file2"])
    df = pd.read_csv(LOG_PATH)
    return df.tail(n).iloc[::-1].reset_index(drop=True)

# ================== –ó–ê–ì–†–£–ó–ö–ê –§–ê–ô–õ–û–í ==================

col1, col2 = st.columns(2)

with col1:
    file1 = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –Ω–∞ –Ω–∞—á–∞–ª—å–Ω—É—é –¥–∞—Ç—É (Excel)", type=["xlsx"])
with col2:
    file2 = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –Ω–∞ –∫–æ–Ω–µ—á–Ω—É—é –¥–∞—Ç—É (Excel)", type=["xlsx"])

if file1 and file2:
    try:
        # --- –ß—Ç–µ–Ω–∏–µ Excel ---
        df1_raw = pd.read_excel(file1, sheet_name="–û—Ç—á–µ—Ç", skiprows=4)
        df2_raw = pd.read_excel(file2, sheet_name="–û—Ç—á–µ—Ç", skiprows=4)

        # --- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è ---
        def filter_data(df: pd.DataFrame) -> pd.DataFrame:
            return df[
                (df["–°–æ—Å—Ç–æ—è–Ω–∏–µ"].isin(["–í —Ä–∞–±–æ—Ç–µ", "–í –ø—Ä–æ—Å—Ç–æ–µ"])) &
                (df["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"] == "–ù–µ—Ñ—Ç—è–Ω–∞—è")
            ]

        filtered_df1 = filter_data(df1_raw)
        filtered_df2 = filter_data(df2_raw)

        # --- –°–æ–±—ã—Ç–∏—è ---
        only_in_df1 = filtered_df1[
            ~filtered_df1["–°–∫–≤–∞–∂–∏–Ω–∞"].isin(filtered_df2["–°–∫–≤–∞–∂–∏–Ω–∞"])
        ]

        only_in_df2 = filtered_df2[
            ~filtered_df2["–°–∫–≤–∞–∂–∏–Ω–∞"].isin(filtered_df1["–°–∫–≤–∞–∂–∏–Ω–∞"])
        ]

        df_merged = filtered_df1.merge(
            filtered_df2,
            on="–°–∫–≤–∞–∂–∏–Ω–∞",
            suffixes=("_df1", "_df2")
        )

        df_changed = df_merged[
            df_merged["–°–ø–æ—Å–æ–± —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏_df1"] != df_merged["–°–ø–æ—Å–æ–± —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏_df2"]
        ]

        out_list = only_in_df1[["–°–∫–≤–∞–∂–∏–Ω–∞"]].copy()
        out_list["–ü–æ—è—Å–Ω–µ–Ω–∏–µ"] = "–í—ã–≤–µ–¥–µ–Ω–æ –∏–∑ –î–§"

        in_list = only_in_df2[["–°–∫–≤–∞–∂–∏–Ω–∞"]].copy()
        in_list["–ü–æ—è—Å–Ω–µ–Ω–∏–µ"] = "–í–≤–µ–¥–µ–Ω–æ –≤ –î–§"

        chg_list = df_changed[["–°–∫–≤–∞–∂–∏–Ω–∞"]].copy()
        chg_list["–ü–æ—è—Å–Ω–µ–Ω–∏–µ"] = "–ó–∞–º–µ–Ω–∞ —Å–ø–æ—Å–æ–±–∞ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏"

        events = pd.concat([out_list, in_list, chg_list], ignore_index=True)

        final_table = (
            events.groupby("–°–∫–≤–∞–∂–∏–Ω–∞", as_index=False)["–ü–æ—è—Å–Ω–µ–Ω–∏–µ"]
            .apply(lambda s: "; ".join(sorted(set(s))))
        )

        # --- –ù–ì–î–£ / –¶–î–ù–ì / –ì–£ ---
        cols_fond = ["–°–∫–≤–∞–∂–∏–Ω–∞", "–ù–ì–î–£", "–¶–î–ù–ì", "–ì–£"]
        missing_fond = [c for c in cols_fond if c not in fond.columns]
        if missing_fond:
            raise ValueError(f"–í fond.csv –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: {missing_fond}")

        meta_fond = fond[cols_fond].drop_duplicates(
            subset=["–°–∫–≤–∞–∂–∏–Ω–∞"], keep="first"
        )

        final_table = final_table.merge(meta_fond, on="–°–∫–≤–∞–∂–∏–Ω–∞", how="left")

        # --- –ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ—Å—Ç–æ—è / –°–ø–æ—Å–æ–± —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏ (–∏–∑ 2-–≥–æ —Ñ–∞–π–ª–∞) ---
        cols_df2 = ["–°–∫–≤–∞–∂–∏–Ω–∞", "–ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ—Å—Ç–æ—è", "–°–ø–æ—Å–æ–± —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏"]
        missing_df2 = [c for c in cols_df2 if c not in filtered_df2.columns]
        if missing_df2:
            raise ValueError(f"–í–æ 2-–º —Ñ–∞–π–ª–µ –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: {missing_df2}")

        meta_df2 = filtered_df2[cols_df2].drop_duplicates(
            subset=["–°–∫–≤–∞–∂–∏–Ω–∞"], keep="first"
        )

        final_table = final_table.merge(meta_df2, on="–°–∫–≤–∞–∂–∏–Ω–∞", how="left")

        # --- sedmax_ip / lora_id ---
        final_table = final_table.merge(main_well, on="–°–∫–≤–∞–∂–∏–Ω–∞", how="left")

        # --- –ü–û–†–Ø–î–û–ö –ö–û–õ–û–ù–û–ö ---
        final_table = final_table[
            [
                "–ù–ì–î–£",
                "–¶–î–ù–ì",
                "–ì–£",
                "–°–∫–≤–∞–∂–∏–Ω–∞",
                "–ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ—Å—Ç–æ—è",
                "–°–ø–æ—Å–æ–± —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏",
                "sedmax_ip",
                "lora_id",
                "–ü–æ—è—Å–Ω–µ–Ω–∏–µ",
            ]
        ]

        final_table = final_table.sort_values(
            ["–ù–ì–î–£", "–¶–î–ù–ì", "–ì–£", "–°–∫–≤–∞–∂–∏–Ω–∞"],
            na_position="last"
        ).reset_index(drop=True)

        # --- –õ–û–ì ---
        log_event(
            event="processed_files",
            file1_name=file1.name,
            file2_name=file2.name
        )

        st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        st.dataframe(final_table, use_container_width=True)

        # --- Excel ---
        def to_excel(df: pd.DataFrame) -> bytes:
            output = BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                df.to_excel(writer, index=False, sheet_name="–†–µ–∑—É–ª—å—Ç–∞—Ç")
            return output.getvalue()

        excel_data = to_excel(final_table)

        downloaded = st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª (Excel)",
            excel_data,
            "–∞–Ω–∞–ª–∏–∑_–¥–∏–Ω–∞–º–∏–∫–∏_—Ñ–æ–Ω–¥–∞.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

        if downloaded:
            log_event(
                event="downloaded_result",
                file1_name=file1.name,
                file2_name=file2.name
            )

        with st.expander("üßæ –õ–æ–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø–∏—Å–µ–π)"):
            st.dataframe(read_last_logs(100), use_container_width=True)

    except Exception as e:
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        st.info(
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:\n"
            "1) –í Excel –µ—Å—Ç—å –ª–∏—Å—Ç '–û—Ç—á–µ—Ç'\n"
            "2) –í–æ 2-–º Excel –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏: –ü—Ä–∏—á–∏–Ω–∞ –ø—Ä–æ—Å—Ç–æ—è, –°–ø–æ—Å–æ–± —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏\n"
            "3) –í fond.csv –µ—Å—Ç—å: –°–∫–≤–∞–∂–∏–Ω–∞, –ù–ì–î–£, –¶–î–ù–ì, –ì–£\n"
            "4) –í main_well.csv –µ—Å—Ç—å: name (–∏–ª–∏ –°–∫–≤–∞–∂–∏–Ω–∞), sedmax_ip, lora_id"
        )
